Shader（着色器）。

渲染流水线的最终目的在于生成或者说是渲染一张二维纹理（显示器上看到的效果），它的输入是一个虚拟摄像机、一些光源、一些Shader以及纹理等。



# 综述

渲染流水线的工作任务在于由一个三维场景出发、生成（渲染）一张二维图像。即，计算机需要从一系列的顶点数据、纹理等信息出发，把这些信息最终转换成一张人眼可以看到的图像。（由CPU和GPU共同完成。）

渲染流程三阶段：应用阶段（Application Stage）、几何阶段（Geometry Stage）、光栅化阶段（Rasterizer Stage）。

## 应用阶段（程序员）

由程序员主导（绝对控制权），CPU负责实现。

最重要的输出是渲染所需的几何信息，即**渲染图元（rendering primitives）**，包括点、线、三角面等。

主要任务：

1. 准备场景数据（摄像机位置、视锥体、场景模型、光源）
2. 粗粒度剔除（culling），把不可见的物体剔除出去，提高渲染性能
3. 设置每个模型的渲染状态：材质（漫反射颜色、高光反射颜色）、纹理、Shader

## 几何阶段（GPU）

出来了所有要绘制的几何相关的事情，例如：决定绘制哪些图元，如何绘制，哪里绘制。

在GPU上进行。

负责和每个渲染图元打交道，进行逐顶点、逐多边形的操作。

把顶点坐标变换到屏幕空间中，再交给光栅器进行处理。

输出：屏幕空间的二维顶点坐标、顶点深度值、着色信息

## 光栅化阶段（GPU）

渲染最终图像。

GPU进行。

决定每个渲染图元中的哪些像素应该被绘制在屏幕上。

对上阶段的逐顶点数据（纹理坐标、顶点颜色）进行插值，再进行逐像素处理。



# CPU和GPU之间的通信

**应用阶段**分为三个阶段：

1. 把数据加载到显存中
2. 设置渲染状态
3. 调用Draw Call

## 把数据加载到显存中

所有渲染所需的数据都需要从**硬盘**（Hard Disk Drive, HDD）中加载到系统**内存**（Random Access Memory, RAM）中，之后，顶点位置、颜色、法线、网格和纹理等数据又被加载到**显存**（Video Random Access Memory, VRAM）中。

之后，开发者需要通过CPU来设置渲染状态，指导GPU进行渲染工作。

## 设置渲染状态

渲染状态定义了场景中的网格是怎样被渲染的，例如：使用哪个顶点着色器（Vertex Shader）/ 片元着色器（Fragment Shader）、光源属性、材质等。

如果没有改变渲染状态，则所有网格都将使用同一种渲染状态。

## 调用Draw Call

渲染命令：Draw Call

发起方：CPU，接收方：GPU

这个命令仅仅会指向一个需要被渲染的图元（primitives）列表，而不会再包含任何材质信息（在上一阶段已经做过）。

当给定了一个Draw Call时，GPU就会根据渲染状态（材质、纹理、着色器等）和所有输入的顶点数据来进行计算，最终输出成屏幕上显示的哪些漂亮的像素。



# GPU流水线

## 概述

GPU渲染的过程就是**GPU流水线**。

<img src="https://huris.oss-cn-hangzhou.aliyuncs.com/blog/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/%E6%B8%B2%E6%9F%93%E6%B5%81%E6%B0%B4%E7%BA%BF/GPU%E6%B5%81%E6%B0%B4%E7%BA%BF.png" width=80%>

几何阶段和光栅化阶段可以分为若干更小的流水线阶段，这些流水线阶段由GPU来实现。

每个阶段GPU提供了不同的可配置性或可编程性。

图中可以看出，GPU的渲染流水线接收**顶点数据**作为输入，这些顶点数据由应用阶段加载到显存中，再由Draw Call指定，随后被传递给顶点着色器。

**几何阶段：**

- **顶点着色器（Vertex Shader）**：完全可编程，实现顶点的空间变换、顶点着色。
- **曲面细分着色器（Tessellation Shader）**：可选着色器，用于细分图元。
- **几何着色器（Geometry Shader）**：可选着色器，执行逐图元（Per-Primitive）着色操作。
- **裁剪（Clipping）**：将那些不在摄像机视野内的顶点裁掉，同时剔除某些三角图元的面片。该阶段可配置，例如，使用自定义裁剪平面配置裁剪区域，或通过指令控制裁剪三角图元的正面还是背面。
- **屏幕映射（Screen Mapping）**：不可配置和编程，负责把每个图元的坐标转换到屏幕坐标系中。

**光栅化阶段：**

- **三角形设置（Triangle Setup）**
- **三角形遍历（Triangle Traversal）**
- **片元着色器（Fragment Shader）**：完全可编程，实现逐片元（Per-Fragment）的着色操作
- **逐片元操作（Per-Fragment Operations）**：修改颜色、深度缓冲、进行混合等，不可编程，但具有很高的可配置性。

## 顶点着色器（Vertex Shader）

流水线第一个阶段，输入来自CPU。

顶点着色器的处理单位是**顶点**，即，输入进来的每个顶点都会调用一次顶点着色器。

顶点着色器本身不创建或者销毁任何顶点，而且无法得到顶点与顶点之间的关系。例如，无法得知两个顶点是否属于同一个三角网格。正是由于这个相互独立性，GPU可以利用本身的特性并行化处理每一个顶点，处理速度会很快。

主要工作：**坐标变换**（把顶点从模型空间转换到齐次裁剪空间，再由硬件做透视除法后，最终得到归一化的设备坐标，Normalized Device Coordinates，NDC）和**逐顶点光照**，还可以输出后续阶段所需的数据。

顶点着色器可以有不同的输出方式，最常见的输出路径是**经光栅化后交给片元着色器**进行处理。

## 裁剪（Clipping）

由于场景可能会很大，而摄像机的视野范围很有可能不会覆盖所有的场景物体，因此那些不在摄像机视野范围的物体不需要被处理。**裁剪**就是为了完成这个目的而被提出来的。

图元与摄像机视野的关系：

1. **完全在视野内**：继续传给下一个流水线阶段。
2. **部分在视野内**：裁剪处理。例如，一条线段的一个顶点在视野内，另一个顶点在视野外，则在视野外部的顶点应该使用一个新的顶点来代替，这个新的顶点位于这条线段和视野边界的交点处。
3. **完全在视野外**：不会继续向下传递，因为它们不需要被渲染。

和顶点着色器不同，这一步是不可编程的，即无法通过编程来控制裁剪的过程，而是硬件上的固定操作，但我们可以自定义一个裁剪操作来对这一步进行配置。

## 屏幕映射（Screen Mapping）

输入的坐标是三维坐标系下的坐标（范围在单位立方体内）。

任务：把每个图元的$x$和$y$坐标转换到屏幕坐标系（Screen Coordinates）。

缩放的过程。

屏幕映射不会对输入的$z$坐标做任何处理。

屏幕坐标系和$z$坐标一起构成了一个坐标系，叫做**窗口坐标系（Window Corrdinates）**，这些值会一起被传递到光栅化阶段。

- **OpenGL**：把屏幕**左下角**当成最小的窗口坐标值。
- **DirectX**：把屏幕**左上角**当成最小的窗口坐标值。

时刻小心这样的差异，**如果发现得到的图像是倒转的**，那么很有可能就是这个原因造成的。

## 三角形设置（Triangle Setup）

这一步开始进入光栅化阶段。

光栅化阶段目标：计算每个图元覆盖了哪些像素，以及为这些像素计算它们的颜色。

该阶段会计算光栅化一个三角网格所需的信息。

光栅化的第一个流水线阶段是**三角形设置（Triangle Setup）**。

该阶段会计算光栅化一个三角网格所需的信息。

上一阶段输出的都是三角网格的顶点，即得到的是三角网格每条边的两个顶点，但如果要得到整个三角网格对像素的覆盖情况，就必须计算每条边上的像素坐标。

为了能够计算边界像素的坐标信息，需要得到三角形边界的表示方式。

这样一个计算三角网格表示数据的过程叫做三角形设置。

## 三角形遍历（Triangle Traversal）

检查每个像素是否被一个三角网格所覆盖，如果被覆盖，就会生成一个片元（fragment），并使用三角网格3个顶点的顶点信息对整个覆盖区域的像素进行插值。

这个阶段也被称为**扫描变换（Scan Conversion）**。

这一步的输出可以得到一个**片元序列**。

一个片元并不是真正意义上的像素，而是**包含了很多状态（屏幕坐标、深度信息、顶点信息、法线、纹理坐标）的集合**，这些状态用于计算每个像素的最终颜色。

## 片元着色器（Fragment Shader）

可编程着色器阶段。

在DirectX中，片元着色器被称为**像素着色器（Pixel Shader）**。

- 片元着色器的输入：上一个阶段对顶点信息插值得到的结果，即那些从顶点着色器中输出的数据插值得到的。
- 片元着色器的输出：一个或者多个颜色值。

该阶段可以完成多个重要的渲染技术，其中最重要的技术之一就是**纹理采样（通常会在顶点着色器阶段输出每个顶点对应的纹理坐标，然后经过光栅化阶段对三角网格的3个顶点对应的纹理坐标进行插值后，就可以得到其覆盖的偏远的纹理坐标了）**。

局限性：仅可以影响单个片元，即，当执行片元着色器时，不可以将自己的任何结果直接发送给它的邻居们。**但有一个情况例外**：片元着色器可以访问到导数信息（gradient/derivative）。

## 逐片元操作（Per-Fragment Operations）

- **OpenGL：**逐片元操作（Per-Fragment Operations）
- **DirectX：**输出合并阶段（Output-Merger）

**主要任务：**

1. 决定每个片元的可见性。涉及很多测试工作，例如：深度测试、模板测试等。
2. 如果一个片元通过了所有的测试，就需要把这个片元的颜色值和已经存储在颜色缓冲区中的颜色进行合并或混合。

逐片元操作是高度**可配置性**的，即我们可以设置每一步的操作细节。

该阶段首先需要解决每个片元的可见性问题（获取和颜色缓冲区进行合并的资格），如果不可见，则这个片元就会被舍弃掉（之前所做的工作都白费了）。

**操作过程：**

片元-->模板测试-->深度测试-->混合-->颜色缓冲区

**【模板测试（Stencil Test）】**

与之相关的是**模板缓冲（Stencil Buffer）**，模板缓冲与颜色缓冲、深度缓冲是一类东西。

如果开启了模板测试，GPU会首先读取（使用读取掩码）模板缓冲区中该片元位置的模板值，然后将该值和读取（使用读取掩码）到的参考值（reference value）进行比较，这个比较函数可由开发者指定（例如：小于时舍弃该片元，或者大于等于时舍弃该片元）。

不管一个片元有没有通过模板测试，都可以根据模板测试和下面的深度测试结果来修改模板缓冲区，这个修改操作是由开发者指定的。

开发者可以设置不同结果下的修改操作，例如：在失败时模板缓冲区保持不变，通过时将模板缓冲区中对应位置的值加1等。

模板测试通常用于限制渲染的区域，还可以进行渲染阴影，轮廓渲染等。

**【深度测试（Depth Test）】**

可以高度配置。

若开启了深度测试，GPU会把该片元的深度值和已经存在于深度缓冲区中的深度值进行比较。该比较函数也可由开发者设置（通常设置为小于等于的关系，即如果该片元深度值大于等于当前深度缓存区中的值，则舍弃它，因为，我们总想只显示出离摄像机最近的物体，而那些被其他物体遮挡的就不需要出现在屏幕上）。

测试顺序不是惟一的，对于大多数GPU来说，它们会尽可能在执行片元着色器之前就进行这些测试（防止：当GPU在片元着色器阶段花了很大力气终于计算出片元的颜色后，却发现这个片元根本没有通过这些检验，则之前花费的计算成本全部浪费了）。

将深度测试提前执行的技术称为：Early-Z技术。

为了避免我们看到那些正在进行光栅化的图元，GPU会使用**双重缓冲（Double Buffering）**，即，对场景的渲染是在幕后发生的，即在**后置缓冲（Back Buffer）**中，一旦场景已经被渲染到了后置缓冲中，GPU就会交换后置缓冲区和**前置缓冲（Front Buffer）**中的内容，由此可以保证看到的图像总是连续的。



# OpenGL/DirectX

图像应用编程接口，这些接口用于渲染二维或三维图形。

架起了上层应用程序和底层GPU的沟通桥梁。

一个应用程序向这些接口发送渲染命令，而这些接口会依次向显卡驱动（Graphics Driver）发送渲染命令，显卡驱动真正和GPU通信，将函数调用翻译成GPU能够听懂的语言，同时也负责将纹理等数据转换成GPU所支持的格式。

由于显卡驱动的存在，几乎所有的GPU都既可以和OpenGL合作，也可以和DirectX合作。



# HLSL/GLSL/CG

在可编程管线出现之前，为了编写着色器代码，开发者需要用汇编语言。

为了方便开发者，就出现了更高级的**着色语言（Shading Language）**。

着色语言是专门用于编写着色器的，常见的着色语言有**DirectX的HLSL**（High Level Shading Language）、**OpenGL的GLSL**（OpenGL Shading Language）以及**NVIDIA的CG**（C for Graphic）。

这些语言会被编译成与机器无关的汇编语言，也被称为**中间语言（Intermediate Language，IL）**。

这些中间语言再交给显卡驱动来翻译成真正的机器语言，即GPU可以理解的语言。

**【GLSL】**

跨平台性，由于OpenGL没有提供着色器编译器，而是由显卡驱动来完成着色器的编译工作。即，只要显卡驱动支持对GLSL的编译它就可以运行。

好处：供应商完全了解自己的硬件构造，他们知道怎样做可以发挥出最大的作用。即，GLSL是依赖硬件，而非操作系统层级的。

但硬件提供商有很多（NVIDIA、ATI等），他们对GLSL的编译实现不尽相同，这可能会造成编译结果不一致的情况。

**【HLSL】**

微软控制着色器的编译，就算使用了不同的硬件，同一个着色器的编译结果也是一样的（版本相同的情况下）。

但是他支持的平台相比有限，几乎都是微软的产品（由于其他平台没有可以编译HLSL的编译器）。

**【CG】**

CG是真正意义上的跨平台。他会根据平台的不同，编译成相应的中间语言。

CG语言的跨平台性很大原因取决于微软的合作，这也导致CG语言的语法和HLSL非常相像，CG语言可以无缝移植成HLSL代码。

但缺点是可能无法完全发挥出OpenGL的最新特性。

在Unity Shader中，我们可以选择使用“CG/HLSL”或者“GLSL”，注意Unity里这些着色语言并不是真正意义上的对应的着色语言，尽管它们的语法几乎一样。



# Draw Call

CPU调用图像编程接口，例如：OpenGL中的`glDrawElements`或DirectX中的`DrawIndexedPrimitive`命令，以命令GPU进行渲染的操作。

## CPU和GPU如何实现并行工作

使用一个**命令缓冲区（Command Buffer）**

命令缓冲区包含一个**命令队列**，由CPU向其中添加命令，而由GPU从中读取命令。（添加和读取的过程是互相独立的）

当CPU需要渲染一些对象时，它可以向命令缓冲区中添加命令，而当GPU完成了上一次的渲染任务后，它就可以从命令队列中再取出一个命令并执行它。

命令缓冲区中的命令有很多种类，`Draw Call`只是其中一种，其他命令还有改变渲染状态（改变使用的着色器、使用不同的纹理）等。

## 为什么Draw Call多了会影响帧率

在每次调用`Draw Call`之前，CPU需要向GPU发送很多内容，包括数据、状态和命令等。

在这一阶段，CPU需要完成很多工作，例如：检查渲染状态等。

一旦CPU完成了这些准备工作，GPU就可以开始本次渲染，GPU的渲染能力是很强的，渲染200个还是2000个三角网格通常没有什么区别，因此渲染速度往往快于CPU提交命令的速度。

如果`Draw Call`的数量太多，CPU就会把大量时间花费在提交`Draw Call`上，造成CPU过载。

## 如果减少Draw Call

**批处理（Batching）**：把很多小的`Draw Call`合并成一个大的`Draw Call`。

由于我们需要在CPU的内存中合并网格，而合并的过程是消耗时间的。因此，批处理技术更加适合于那些**静态的物体**，例如不会移动的大地，石头等，对于这些静态的物体，我们只需要合并一次即可。

如果对动态物体进行批处理，由于物体是不断运动的，因此每一帧都需要重新进行合并然后再发给GPU，这对空间和时间都会造成一定的影响。

- 避免使用大量很小的网格。当不可避免地需要使用很小的网格结构时，考虑是否可以合并它们。
- 避免使用过多的材质。尽量在不同的网格之间共用同一个材质。



# 固定管线渲染

固定管线，又称**固定函数的流水线（Fixed-Function Pipeline）**

指在较旧的GPU上实现的渲染流水线。这种流水线只给开发者提供一些配置操作，但开发者没有对流水线阶段的完全控制权。

固定管线通常提供了一系列接口（由开发者控制），这些接口包含了一个**函数入口点（Function Entry Points）集合**，这些函数入口点会匹配GPU上的一个特定的逻辑功能。

固定渲染管线是只可配置的管线。

随着GPU流水线越来越朝着更高的灵活性和可控性方向发展，可编程渲染管线应运而生，固定管线逐渐退出历史舞台。















